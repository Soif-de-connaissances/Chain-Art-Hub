{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df3ba8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 254ms/step\n",
      "1/1 [==============================] - 0s 284ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "4/4 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 325ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "4/4 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "4/4 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "MoviePy - Writing audio in temp_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in temp_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "face similarity is 0.9539943337440491\n",
      "voice similarity is 0.8034164309501648\n",
      "身份验证通过\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from mtcnn import MTCNN\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import librosa\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "# 1. 加载 MTCNN 模型\n",
    "mtcnn = MTCNN()\n",
    "\n",
    "# 2. 加载预训练的 ResNet50 模型\n",
    "resnet50 = models.resnet50(pretrained=True)\n",
    "resnet50.eval()\n",
    "\n",
    "# 3. 移除最后的全连接层，用于特征提取\n",
    "resnet50 = torch.nn.Sequential(*list(resnet50.children())[:-1])\n",
    "\n",
    "# 定义图像预处理的转换\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "#文件路径\n",
    "old_path = r\"C:\\Users\\50597\\Desktop\\1.mp4\"\n",
    "new_path = r\"C:\\Users\\50597\\Desktop\\2.mp4\"\n",
    "\n",
    "# 图片人脸特征识别模块\n",
    "def extract_face_features(image):\n",
    "    image = Image.fromarray(image)\n",
    "    result = mtcnn.detect_faces(np.array(image))\n",
    "    if not result:\n",
    "        print(\"No face detected.\")\n",
    "        return None\n",
    "    face = result[0]\n",
    "    x, y, width, height = face['box']\n",
    "    face = image.crop((x, y, x + width, y + height))\n",
    "    face_image = face\n",
    "    face_tensor = preprocess(face_image)\n",
    "    face_tensor = face_tensor.unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        features = resnet50(face_tensor)\n",
    "    features = features.squeeze()\n",
    "    return features\n",
    "\n",
    "# 视频人脸特征识别模块\n",
    "def extract_video_features(video_path, num_frames=30):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    total_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    frame_indices = np.linspace(0, total_frames - 1, num_frames)\n",
    "    features_list = []\n",
    "    for index in frame_indices:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, index)\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            features = extract_face_features(frame)\n",
    "            if features is not None:\n",
    "                features_list.append(features)\n",
    "    cap.release()\n",
    "    if len(features_list) > 0:\n",
    "        features_mean = torch.stack(features_list).mean(dim=0)\n",
    "        return features_mean\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "#音频特征提取模块\n",
    "def extract_audio_feature_from_video(video_path, sample_rate=16000):\n",
    "    # 加载预训练的 VGGish 模型\n",
    "    vggish_model = hub.load('https://tfhub.dev/google/vggish/1')\n",
    "    # 使用 moviepy 从视频中提取音频\n",
    "    video_clip = VideoFileClip(video_path)\n",
    "    audio_clip = video_clip.audio\n",
    "    # 将音频保存为临时文件\n",
    "    temp_audio_path = 'temp_audio.wav'\n",
    "    audio_clip.write_audiofile(temp_audio_path)\n",
    "    # 使用 librosa 加载音频数据和采样率\n",
    "    y, sr = librosa.load(temp_audio_path, sr=sample_rate)  # VGGish 要求采样率为 16kHz\n",
    "    # 将音频转换为所需的输入格式\n",
    "    input_data = y.astype(np.float32)\n",
    "    # 由于VGGish模型要求输入是任意长度的1-D Tensor，我们不需要增加 batch dimension\n",
    "    # 直接使用input_data作为模型的输入\n",
    "    # 使用 VGGish 提取特征\n",
    "    features = vggish_model(input_data)\n",
    "    return torch.tensor(features.numpy())\n",
    "\n",
    "# 相似度计算模块\n",
    "def cos_similarity(feat1, feat2):\n",
    "    feat1 = feat1.flatten()\n",
    "    feat2 = feat2.flatten()\n",
    "    similarity = F.cosine_similarity(feat1.unsqueeze(0), feat2.unsqueeze(0))\n",
    "    return similarity.item()\n",
    "\n",
    "\n",
    "# 对比模块\n",
    "def compare(old_path, new_path, threshold=0.8):\n",
    "    old_face_feature = extract_video_features(old_path, num_frames=2)\n",
    "    new_face_feature = extract_video_features(new_path, num_frames=2)\n",
    "    face_similarity = cos_similarity(old_face_feature, new_face_feature)\n",
    "    old_voice_feature = extract_audio_feature_from_video(old_path)\n",
    "    new_voice_feature = extract_audio_feature_from_video(new_path)\n",
    "    voice_similarity = cos_similarity(old_voice_feature, new_voice_feature)\n",
    "    print(f'face similarity is {face_similarity}')\n",
    "    print(f'voice similarity is {voice_similarity}')\n",
    "    if face_similarity >= threshold and voice_similarity >= threshold:\n",
    "        print('身份验证通过')\n",
    "    elif face_similarity <= threshold and voice_similarity >= threshold:\n",
    "        print('人脸未通过验证')\n",
    "    elif face_similarity >= threshold and voice_similarity <= threshold:\n",
    "        print('声音未通过验证')\n",
    "    else:\n",
    "        print('人脸和声音均未通过验证')\n",
    "\n",
    "compare(old_path, new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d700b99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
